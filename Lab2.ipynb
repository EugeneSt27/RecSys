{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0214df4f-9112-4949-956d-ce77c1501c78",
   "metadata": {},
   "source": [
    "# 0. Импорт библиотек, задание функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cde08459-6b22-4564-a194-2cc66ed96743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1a498-5b49-43d4-a26a-1a1185ae8d58",
   "metadata": {},
   "source": [
    "# 1. Загрузка датасета, разбиение на train test, создание матриц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fedb18d6-9b93-48a1-8935-e4463dd948bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета: (100836, 4)\n",
      "Уникальные пользователи: 610\n",
      "Уникальные фильмы: 9724\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('movie_data/ratings.csv')\n",
    "movies = pd.read_csv('movie_data/movies.csv')\n",
    "\n",
    "print('Размер датасета:', ratings.shape)\n",
    "print('Уникальные пользователи:', ratings['userId'].nunique())\n",
    "print('Уникальные фильмы:', ratings['movieId'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bee283-1a72-4648-bbda-9763cb5495ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 70585\n",
      "Размер тестовой выборки: 30251\n"
     ]
    }
   ],
   "source": [
    "ratings_sorted = ratings.sort_values(by='timestamp')\n",
    "train_size = int(0.7 * len(ratings_sorted))\n",
    "\n",
    "train_df = ratings_sorted.iloc[:train_size].copy()\n",
    "test_df = ratings_sorted.iloc[train_size:].copy()\n",
    "\n",
    "print(f'Размер обучающей выборки: {len(train_df)}')\n",
    "print(f'Размер тестовой выборки: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25cc8f15-d4ef-497c-ab11-93b62e76b926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b64d1f3d-5406-481e-86ff-063b48dda3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = sorted(ratings['userId'].unique())\n",
    "all_items = sorted(ratings['movieId'].unique())\n",
    "user_to_index = {user: i for i, user in enumerate(all_users)}\n",
    "item_to_index = {item: i for i, item in enumerate(all_items)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94f26f38-08a0-41bf-8e42-59b1ca8993ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 9724)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = len(all_users)\n",
    "n_items = len(all_items)\n",
    "\n",
    "R_train = np.zeros((n_users, n_items))\n",
    "for _, row in train_df.iterrows():\n",
    "    u = user_to_index[row['userId']]\n",
    "    i = item_to_index[row['movieId']]\n",
    "    R_train[u, i] = row['rating']\n",
    "\n",
    "R_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c887da-ea0d-4982-867f-5b6e8116f159",
   "metadata": {},
   "source": [
    "# 2. Реализация SVD через SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4035cb50-5f7a-4b28-b0e1-c815cf906ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 50  # Количество латентых факторов\n",
    "learning_rate = 0.005\n",
    "regularization_param = 0.02\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c824b145-c0e2-4fb9-ad10-9840b85c7e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало обучения Funk SVD...\n",
      "Обучение Funk SVD завершено.\n"
     ]
    }
   ],
   "source": [
    "P = np.random.rand(n_users, K) * 0.1\n",
    "Q = np.random.rand(n_items, K) * 0.1\n",
    "\n",
    "mu = np.mean(R_train[R_train > 0])\n",
    "\n",
    "b_u = np.zeros(n_users) # баес пользователя\n",
    "b_i = np.zeros(n_items) # баес предмета\n",
    "\n",
    "print('Начало обучения Funk SVD')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for u_idx in range(n_users):\n",
    "        for i_idx in range(n_items):\n",
    "            if R_train[u_idx, i_idx] > 0:\n",
    "                r_ui = R_train[u_idx, i_idx]\n",
    "                # Предсказание рейтинга по формуле: r = mu + b_u + b_i + P_u * Q_i^T\n",
    "                r_hat_ui = mu + b_u[u_idx] + b_i[i_idx] + np.dot(P[u_idx, :], Q[i_idx, :])\n",
    "\n",
    "                error = r_ui - r_hat_ui\n",
    "                \n",
    "                # Обновление баесов\n",
    "                b_u[u_idx] += learning_rate * (error - regularization_param * b_u[u_idx])\n",
    "                b_i[i_idx] += learning_rate * (error - regularization_param * b_i[i_idx])\n",
    "                \n",
    "                # Обновление матриц латентных факторов\n",
    "                P[u_idx, :] += learning_rate * (error * Q[i_idx, :] - regularization_param * P[u_idx, :])\n",
    "                Q[i_idx, :] += learning_rate * (error * P[u_idx, :] - regularization_param * Q[i_idx, :])\n",
    "\n",
    "print('Обучение Funk SVD завершено')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91e69efc-64e2-44dc-bd30-bbb0cf380dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred = mu + b_u[:, np.newaxis] + b_i[np.newaxis, :] + np.dot(P, Q.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285c0d9-925a-4418-b2b9-b828922e5c27",
   "metadata": {},
   "source": [
    "# 3. Функции расчета метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f59b851e-02e8-40ff-b29f-f473b3c17cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_precision_at_k(recommended_items, relevant_items, k):\n",
    "    '''Рассчитывает Average Precision@K (AP@K).'''\n",
    "    if not relevant_items:\n",
    "        return 0.0\n",
    "    \n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    \n",
    "    for i in range(k):\n",
    "        item = recommended_items[i]\n",
    "        if item in relevant_items:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    return score / min(len(relevant_items), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "250b98e6-b67b-457a-a03f-5761c484e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dcg_at_k(recommended_items, relevant_items_scores, k):\n",
    "    '''Рассчитывает DCG@K. relevant_items_scores - словарь {item: score}.'''\n",
    "    dcg = 0.0\n",
    "    for i in range(k):\n",
    "        item = recommended_items[i]\n",
    "        if item in relevant_items_scores:\n",
    "            gain = 2**relevant_items_scores[item] - 1\n",
    "        else:\n",
    "            gain = 0\n",
    "        dcg += gain / np.log2(i + 2) # индексация с 0 поэтому 2 а не 1\n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66869f39-71de-4225-8ab8-018d6e3dc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg_at_k(recommended_items, relevant_items_scores, k):\n",
    "    '''Рассчитывает NDCG@K.'''\n",
    "    dcg = calculate_dcg_at_k(recommended_items, relevant_items_scores, k)\n",
    "    idcg_gains = sorted(\n",
    "        [2**score - 1 for score in relevant_items_scores.values()], \n",
    "        reverse=True)[:k]\n",
    "    \n",
    "    idcg = 0.0\n",
    "    for i, gain in enumerate(idcg_gains):\n",
    "        idcg += gain / np.log2(i + 2)\n",
    "        \n",
    "    # 3. NDCG\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba79c2f-378d-4bb2-910a-a0acfbe55157",
   "metadata": {},
   "source": [
    "# Расчет метрик на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e663fa3f-b430-46e4-8142-4a31af5e5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_METRIC = 50\n",
    "RELEVANCE_THRESHOLD = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b065c74-d555-42a7-bb92-668698799283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19396\\1513054882.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_user_ratings = test_df.groupby('userId').apply(\n"
     ]
    }
   ],
   "source": [
    "test_user_ratings = test_df.groupby('userId').apply(\n",
    "    lambda x: dict(zip(x['movieId'], x['rating']))\n",
    ").to_dict()\n",
    "\n",
    "test_users = [u for u in test_user_ratings.keys() if u in user_to_index] # берем пользоваетелей которые есть в трейне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf1d88c2-5a98-42b8-a65c-3c217c0da09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расчет MAP@50 и NDCG@50 для SVD...\n",
      "\n",
      "--- Результаты SVD (Funk SVD) ---\n",
      "MAP@50: 0.0851\n",
      "NDCG@50: 0.2019\n"
     ]
    }
   ],
   "source": [
    "all_ap_scores = []\n",
    "all_ndcg_scores = []\n",
    "\n",
    "print(f'Расчет MAP@{K_METRIC} и NDCG@{K_METRIC} для SVD...')\n",
    "\n",
    "for user_id in test_users:\n",
    "    u_idx = user_to_index[user_id]\n",
    "    rated_items_train_indices = np.where(R_train[u_idx, :] > 0)[0] # ищем уже оцененные пользователем предметы\n",
    "    user_predictions = R_pred[u_idx, :] # предсказания для всех предметов i пользователя\n",
    "\n",
    "    temp_predictions = user_predictions.copy()\n",
    "    temp_predictions[rated_items_train_indices] = -np.inf # искл уже оцененные пользователем предметы\n",
    "\n",
    "    recommended_indices = np.argsort(temp_predictions)[::-1] # индексы лучших предсказаний\n",
    "    index_to_item = {i: item for item, i in item_to_index.items()}\n",
    "    recommended_items_id = [index_to_item[i] for i in recommended_indices]\n",
    "    \n",
    "    relevant_items_test_scores = test_user_ratings[user_id]\n",
    "\n",
    "    relevant_items_id = {\n",
    "        item: score \n",
    "        for item, score in relevant_items_test_scores.items() \n",
    "        if score >= RELEVANCE_THRESHOLD\n",
    "    }\n",
    "\n",
    "    ap_score = calculate_average_precision_at_k(\n",
    "        recommended_items_id, \n",
    "        list(relevant_items_id.keys()), \n",
    "        K_METRIC\n",
    "    )\n",
    "    all_ap_scores.append(ap_score)\n",
    "\n",
    "    ndcg_score = calculate_ndcg_at_k(\n",
    "        recommended_items_id, \n",
    "        relevant_items_id,\n",
    "        K_METRIC\n",
    "    )\n",
    "    all_ndcg_scores.append(ndcg_score)\n",
    "\n",
    "MAP_K_SVD = np.mean(all_ap_scores)\n",
    "NDCG_K_SVD = np.mean(all_ndcg_scores)\n",
    "\n",
    "print(f'MAP@{K_METRIC}: {MAP_K_SVD:.4f}')\n",
    "print(f'NDCG@{K_METRIC}: {NDCG_K_SVD:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb3c77-f0ec-4334-99cf-13ad3d3eb1b9",
   "metadata": {},
   "source": [
    "# Сравнение с item-based и user-based из первой лабы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e8fbc17a-2eb5-4e2f-b2a8-7919ac0d2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция косинусной близости\n",
    "def cosine_similarity(vec1, vec2): \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0\n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1a423-2032-4ccf-89e2-892a73980442",
   "metadata": {},
   "source": [
    "Ниже код из первой лабы для сравнения метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52afd02-05bd-4504-a3f6-b187574b9770",
   "metadata": {},
   "source": [
    "## User-based, расчет новых метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ef9ea3f4-648e-40a8-b88e-3fb7d6dc998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(ratings, test_size=0.3, random_state=42)\n",
    "unique_users = np.unique(ratings.to_numpy()[:, 0]) # уникальные юзеры\n",
    "unique_movies = np.unique(ratings.to_numpy()[:, 1]) # уникальные фильмы\n",
    "user_id_dict = {user_id: i for i, user_id in enumerate(unique_users)}\n",
    "movie_id_dict = {movie_id: i for i, movie_id in enumerate(unique_movies)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "484acea2-dc20-441c-9e31-bd726c87feea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало расчета полной матрицы сходства пользователей\n",
      "Матрица сходства пользователей готова\n"
     ]
    }
   ],
   "source": [
    "#user-based из первой лабы\n",
    "user_item_matrix = np.zeros((len(unique_users), len(unique_movies)))\n",
    "for user_id, movie_id, rating, _ in train_data.to_numpy():\n",
    "    user_idx = user_id_dict[user_id]\n",
    "    movie_idx = movie_id_dict[movie_id]\n",
    "    user_item_matrix[user_idx, movie_idx] = rating\n",
    "\n",
    "# расчет матрицы сходства\n",
    "n_users = len(unique_users)\n",
    "user_similarity_matrix = np.zeros((n_users, n_users))\n",
    "\n",
    "print('Начало расчета полной матрицы сходства пользователей')\n",
    "for u_idx in range(n_users):\n",
    "    for v_idx in range(u_idx, n_users): \n",
    "        if u_idx == v_idx:\n",
    "            user_similarity_matrix[u_idx, v_idx] = 1.0\n",
    "        else:\n",
    "            sim = cosine_similarity(user_item_matrix[u_idx, :], user_item_matrix[v_idx, :]) \n",
    "            user_similarity_matrix[u_idx, v_idx] = sim\n",
    "            user_similarity_matrix[v_idx, u_idx] = sim # Заполняем симметрично\n",
    "\n",
    "print('Матрица сходства пользователей готова')\n",
    "\n",
    "\n",
    "def predict_user_based_optimized(user_id, movie_id):\n",
    "    if user_id not in user_id_dict or movie_id not in movie_id_dict:\n",
    "        return np.nan\n",
    "    \n",
    "    u_idx = user_id_dict[user_id]\n",
    "    i_idx = movie_id_dict[movie_id]\n",
    "    u_ratings = user_item_matrix[u_idx, :]\n",
    "    r_u_bar = u_ratings[u_ratings > 0].mean() if np.any(u_ratings > 0) else 0.0\n",
    "    v_indices_rated_item = np.where(user_item_matrix[:, i_idx] > 0)[0]\n",
    "    v_indices_rated_item = v_indices_rated_item[v_indices_rated_item != u_idx] # Исключаем u\n",
    "    \n",
    "    if len(v_indices_rated_item) == 0:\n",
    "        return r_u_bar\n",
    "    all_similarities = user_similarity_matrix[u_idx, v_indices_rated_item]\n",
    "    sorted_indices = np.argsort(np.abs(all_similarities))[::-1]\n",
    "    top_n_indices = v_indices_rated_item[sorted_indices[:N_NEIGHBORS]]\n",
    "    \n",
    "    chisl = 0.0\n",
    "    znam = 0.0\n",
    "    \n",
    "    for v_idx in top_n_indices:\n",
    "        sim_uv = user_similarity_matrix[u_idx, v_idx]\n",
    "\n",
    "        r_v_bar = user_item_matrix[v_idx, :][user_item_matrix[v_idx, :] > 0].mean() \n",
    "        r_vi = user_item_matrix[v_idx, i_idx]\n",
    "        \n",
    "        chisl += sim_uv * (r_vi - r_v_bar)\n",
    "        znam += abs(sim_uv)\n",
    "        \n",
    "    if znam == 0:\n",
    "        return r_u_bar\n",
    "    predicted_rating = r_u_bar + (chisl / znam)\n",
    "    return np.clip(predicted_rating, 1.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7e2e6ca4-da37-4749-9126-1ac0ebcc1616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19396\\4120490060.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  test_user_ratings = test_data.groupby(test_data.columns[0]).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало расчета MAP@50 и NDCG@50 для User-Based CF\n",
      "\n",
      "--- Результаты User-Based CF (Оптимизированный) ---\n",
      "MAP@50: 0.0008\n",
      "NDCG@50: 0.0049\n"
     ]
    }
   ],
   "source": [
    "N_NEIGHBORS = 50\n",
    "\n",
    "test_user_ratings = test_data.groupby(test_data.columns[0]).apply(\n",
    "    lambda x: dict(zip(x.iloc[:, 1], x.iloc[:, 2]))\n",
    ").to_dict()\n",
    "\n",
    "test_users_cf = [u for u in test_user_ratings.keys() if u in user_id_dict]\n",
    "all_items_list = list(movie_id_dict.keys())\n",
    "\n",
    "all_ap_scores_cf = []\n",
    "all_ndcg_scores_cf = []\n",
    "\n",
    "print(f'Начало расчета MAP@{K_METRIC} и NDCG@{K_METRIC} для User-Based CF')\n",
    "\n",
    "for user_id in test_users_cf:\n",
    "    user_predictions_map = {}\n",
    "    user_idx = user_id_dict[user_id]\n",
    "    rated_items_indices_train = np.where(user_item_matrix[user_idx, :] > 0)[0] # Исключение фильмов, оцененных в TRAIN\n",
    "    index_to_movie_id = {idx: movie_id for movie_id, idx in movie_id_dict.items()}\n",
    "    rated_items_id_train = {index_to_movie_id[idx] for idx in rated_items_indices_train}\n",
    "\n",
    "    for movie_id in all_items_list:\n",
    "        if movie_id not in rated_items_id_train:\n",
    "            predicted_rating = predict_user_based_optimized(user_id, movie_id) \n",
    "            if not np.isnan(predicted_rating):\n",
    "                user_predictions_map[movie_id] = predicted_rating\n",
    "\n",
    "    # Ранжирование\n",
    "    recommended_items_id_cf = sorted(\n",
    "        user_predictions_map, \n",
    "        key=user_predictions_map.get, \n",
    "        reverse=True\n",
    "    )[:K_METRIC]\n",
    "\n",
    "    relevant_items_test_scores = test_user_ratings[user_id]\n",
    "    \n",
    "    relevant_items_id_list = [item for item, score in relevant_items_test_scores.items() if score >= RELEVANCE_THRESHOLD]\n",
    "    relevant_items_id_scores = {item: score for item, score in relevant_items_test_scores.items() if score >= RELEVANCE_THRESHOLD}\n",
    "\n",
    "    all_ap_scores_cf.append(calculate_average_precision_at_k(recommended_items_id_cf, relevant_items_id_list, K_METRIC))\n",
    "    all_ndcg_scores_cf.append(calculate_ndcg_at_k(recommended_items_id_cf, relevant_items_id_scores, K_METRIC))\n",
    "\n",
    "# ФИНАЛЬНЫЕ МЕТРИКИ\n",
    "MAP_K_CF_USER = np.mean(all_ap_scores_cf)\n",
    "NDCG_K_CF_USER = np.mean(all_ndcg_scores_cf)\n",
    "\n",
    "print('Результаты User-Based CF')\n",
    "print(f'MAP@{K_METRIC}: {MAP_K_CF_USER:.4f}')\n",
    "print(f'NDCG@{K_METRIC}: {NDCG_K_CF_USER:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eefae8-1b58-49dc-9bb3-e5b75526a1b7",
   "metadata": {},
   "source": [
    "## item-based, расчет новых метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "da8fb1bb-3bb9-46d4-a287-412900dd7eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало расчета полной матрицы сходства предметов\n",
      "Матрица сходства предметов готова\n",
      "Размер матрицы сходства: (9724, 9724)\n"
     ]
    }
   ],
   "source": [
    "item_user_matrix = np.zeros((len(unique_movies), len(unique_users)))\n",
    "for user_id, movie_id, rating, _ in train_data.to_numpy():\n",
    "    user_idx = user_id_dict[user_id]\n",
    "    movie_idx = movie_id_dict[movie_id]\n",
    "    item_user_matrix[movie_idx, user_idx] = rating\n",
    "\n",
    "n_items = len(unique_movies)\n",
    "item_similarity_matrix = np.zeros((n_items, n_items))\n",
    "\n",
    "print('Начало расчета полной матрицы сходства предметов')\n",
    "\n",
    "for i_idx in range(n_items):\n",
    "    for j_idx in range(i_idx, n_items):\n",
    "        if i_idx == j_idx:\n",
    "            item_similarity_matrix[i_idx, j_idx] = 1.0\n",
    "        else:\n",
    "            # сравниваем векторы оценок фильмов)\n",
    "            sim = cosine_similarity(item_user_matrix[i_idx, :], item_user_matrix[j_idx, :]) \n",
    "            item_similarity_matrix[i_idx, j_idx] = sim\n",
    "            item_similarity_matrix[j_idx, i_idx] = sim # Заполняем симметрично\n",
    "\n",
    "print('Матрица сходства предметов готова')\n",
    "print(f'Размер матрицы сходства: {item_similarity_matrix.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "16b2abc6-951a-44aa-b8e2-e87010cdd7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = 50 \n",
    "\n",
    "def predict_item_based_optimized(user_id, movie_id):\n",
    "    if user_id not in user_id_dict or movie_id not in movie_id_dict:\n",
    "        return np.nan\n",
    "    \n",
    "    u_idx = user_id_dict[user_id]\n",
    "    i_idx = movie_id_dict[movie_id]\n",
    "    i_ratings = item_user_matrix[i_idx, :]\n",
    "    r_i_bar = i_ratings[i_ratings > 0].mean() if np.any(i_ratings > 0) else 0.0\n",
    "\n",
    "    j_indices_rated_by_user = np.where(item_user_matrix[:, u_idx] > 0)[0]\n",
    "    j_indices_rated_by_user = j_indices_rated_by_user[j_indices_rated_by_user != i_idx]\n",
    "    \n",
    "    if len(j_indices_rated_by_user) == 0:\n",
    "        return r_i_bar\n",
    "    all_similarities = item_similarity_matrix[i_idx, j_indices_rated_by_user]\n",
    "    sorted_indices = np.argsort(np.abs(all_similarities))[::-1]\n",
    "    top_n_indices = j_indices_rated_by_user[sorted_indices[:N_NEIGHBORS]]\n",
    "    \n",
    "    chisl = 0.0\n",
    "    znam = 0.0\n",
    "    \n",
    "    for j_idx in top_n_indices:\n",
    "        sim_ij = item_similarity_matrix[i_idx, j_idx]\n",
    "        r_j_bar = item_user_matrix[j_idx, :][item_user_matrix[j_idx, :] > 0].mean() \n",
    "        r_ju = item_user_matrix[j_idx, u_idx]\n",
    "        \n",
    "        chisl += sim_ij * (r_ju - r_j_bar)\n",
    "        znam += abs(sim_ij)\n",
    "        \n",
    "    if znam == 0:\n",
    "        return r_i_bar\n",
    "    \n",
    "    predicted_rating = r_i_bar + (chisl / znam)\n",
    "    return np.clip(predicted_rating, 1.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "988b0c17-bab4-47db-8588-db89a98892bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало расчета MAP@50 и NDCG@50.\n",
      "\n",
      " Результаты\n",
      "MAP@50: 0.0005\n",
      "NDCG@50: 0.0031\n"
     ]
    }
   ],
   "source": [
    "all_ap_scores_cf_item = []\n",
    "all_ndcg_scores_cf_item = []\n",
    "\n",
    "print(f\"Начало расчета MAP@{K_METRIC} и NDCG@{K_METRIC}.\")\n",
    "\n",
    "for user_id in test_users_cf:\n",
    "    user_predictions_map = {}\n",
    "    u_idx = user_id_dict[user_id]\n",
    "\n",
    "    index_to_movie_id = {idx: movie_id for movie_id, idx in movie_id_dict.items()}\n",
    "    rated_items_indices_train = np.where(item_user_matrix[:, u_idx] > 0)[0] \n",
    "    rated_items_id_train = {index_to_movie_id[idx] for idx in rated_items_indices_train}\n",
    "\n",
    "    for movie_id in all_items_list:\n",
    "        if movie_id not in rated_items_id_train:\n",
    "            predicted_rating = predict_item_based_optimized(user_id, movie_id) \n",
    "            if not np.isnan(predicted_rating):\n",
    "                user_predictions_map[movie_id] = predicted_rating\n",
    "\n",
    "    recommended_items_id_cf = sorted(\n",
    "        user_predictions_map, \n",
    "        key=user_predictions_map.get, \n",
    "        reverse=True\n",
    "    )[:K_METRIC]\n",
    "\n",
    "    relevant_items_test_scores = test_user_ratings[user_id]\n",
    "    relevant_items_id_list = [item for item, score in relevant_items_test_scores.items() if score >= RELEVANCE_THRESHOLD]\n",
    "    relevant_items_id_scores = {item: score for item, score in relevant_items_test_scores.items() if score >= RELEVANCE_THRESHOLD}\n",
    "\n",
    "    all_ap_scores_cf_item.append(calculate_average_precision_at_k(recommended_items_id_cf, relevant_items_id_list, K_METRIC))\n",
    "    all_ndcg_scores_cf_item.append(calculate_ndcg_at_k(recommended_items_id_cf, relevant_items_id_scores, K_METRIC))\n",
    "\n",
    "MAP_K_CF_ITEM = np.mean(all_ap_scores_cf_item)\n",
    "NDCG_K_CF_ITEM = np.mean(all_ndcg_scores_cf_item)\n",
    "\n",
    "print(\"\\n Результаты\")\n",
    "print(f\"MAP@{K_METRIC}: {MAP_K_CF_ITEM:.4f}\")\n",
    "print(f\"NDCG@{K_METRIC}: {NDCG_K_CF_ITEM:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1cca8-85a6-46b8-a33e-fcc912fdcaaa",
   "metadata": {},
   "source": [
    "# 4. Сравнение подходов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507c668c-8bcc-42c5-b52b-3d2a5312c48e",
   "metadata": {},
   "source": [
    "Сравнение показало, что Матричная Факторизация (SVD) **значительно превосходит** подходы коллаборативной фильтрации, основанные на близости (User-based и Item-based), по всем метрикам качества.\n",
    "\n",
    "Ключевое преимущество SVD заключается в эффективном **преодолении разреженности данных**: она использует латентные факторы для обобщения предпочтений, что позволяет делать более точные прогнозы, чем простые корреляции между явными оценками. \n",
    "User/Item-based методы критически зависят от наличия явных, пересекающихся оценок, SVD более масштабируема и надежна.\n",
    "\n",
    "Но SVD имеет существенный недостаток: она страдает от проблемы \"холодного старта\" для новых сущностей и предлагает рекомендации с низкой интерпретируемостью.\n",
    "\n",
    "Таким образом, SVD является наиболее точным базовым алгоритмом, но требует гибридизации для полного решения проблем реального мира."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a0c2c3-15e1-4dd0-9c59-eb3ed1a3926c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
